"""
åœºæ™¯ç”Ÿæˆç³»ç»Ÿ - AIå®¢æˆ·ç«¯æ¨¡å—

å°è£…DeepSeek APIè°ƒç”¨ï¼Œæä¾›åœºæ™¯ç”Ÿæˆæ‰€éœ€çš„AIèƒ½åŠ›
"""

import json
import time
import asyncio
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import httpx


@dataclass
class AIConfig:
    """AIé…ç½®"""
    api_key: str = "sk-41b5fa62f0a445bea376f5852ed686c2"
    base_url: str = "https://api.deepseek.com"
    model: str = "deepseek-chat"
    temperature: float = 0.7
    max_tokens: int = 4096
    timeout: float = 60.0


class AIClient:
    """
    DeepSeek AIå®¢æˆ·ç«¯
    
    å°è£…APIè°ƒç”¨ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æ¨¡å¼
    """
    
    def __init__(self, config: Optional[AIConfig] = None):
        self.config = config or AIConfig()
        self.headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }
    
    def _build_request_body(
        self, 
        messages: List[Dict[str, str]], 
        **kwargs
    ) -> Dict[str, Any]:
        """æž„å»ºè¯·æ±‚ä½“"""
        return {
            "model": kwargs.get("model", self.config.model),
            "messages": messages,
            "temperature": kwargs.get("temperature", self.config.temperature),
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens),
        }
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """è§£æžJSONå“åº”"""
        try:
            # å°è¯•ç›´æŽ¥è§£æž
            return json.loads(content)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONå—
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end > start:
                    return json.loads(content[start:end].strip())
            elif "```" in content:
                start = content.find("```") + 3
                end = content.find("```", start)
                if end > start:
                    return json.loads(content[start:end].strip())
            
            # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡
            start = content.find("{")
            end = content.rfind("}") + 1
            if start >= 0 and end > start:
                return json.loads(content[start:end])
            
            raise ValueError(f"æ— æ³•è§£æžJSONå“åº”: {content[:200]}...")
    
    def chat(
        self, 
        messages: List[Dict[str, str]], 
        **kwargs
    ) -> Dict[str, Any]:
        """
        åŒæ­¥è°ƒç”¨AIå¯¹è¯
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆmodel, temperature, max_tokensç­‰ï¼‰
        
        Returns:
            è§£æžåŽçš„JSONå“åº”
        """
        url = f"{self.config.base_url}/v1/chat/completions"
        body = self._build_request_body(messages, **kwargs)
        
        with httpx.Client(timeout=self.config.timeout) as client:
            response = client.post(url, headers=self.headers, json=body)
            response.raise_for_status()
            result = response.json()
        
        content = result["choices"][0]["message"]["content"]
        return self._parse_json_response(content)
    
    async def chat_async(
        self, 
        messages: List[Dict[str, str]], 
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¼‚æ­¥è°ƒç”¨AIå¯¹è¯
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            è§£æžåŽçš„JSONå“åº”
        """
        url = f"{self.config.base_url}/v1/chat/completions"
        body = self._build_request_body(messages, **kwargs)
        
        async with httpx.AsyncClient(timeout=self.config.timeout) as client:
            response = await client.post(url, headers=self.headers, json=body)
            response.raise_for_status()
            result = response.json()
        
        content = result["choices"][0]["message"]["content"]
        return self._parse_json_response(content)


class SceneAIPrompts:
    """
    åœºæ™¯ç”ŸæˆAIæç¤ºè¯æ¨¡æ¿
    
    æä¾›å„ç§åœºæ™¯ç”Ÿæˆä»»åŠ¡çš„æç¤ºè¯æ¨¡æ¿
    """
    
    @staticmethod
    def get_system_prompt() -> str:
        """èŽ·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœºæ™¯è®¾è®¡å¸ˆï¼Œè´Ÿè´£æ ¹æ®å‰§æœ¬å’Œåœºæ™¯éœ€æ±‚ç”Ÿæˆè¯¦ç»†çš„åœºæ™¯å…ƒç´ ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆåœºæ™¯ä¸­çš„ç‰©å“å’Œå®¹å™¨èŠ‚ç‚¹ã€‚

## èŠ‚ç‚¹ç±»åž‹è¯´æ˜Ž

1. **ç‰©å“èŠ‚ç‚¹ (item)**: æœ«ç«¯èŠ‚ç‚¹ï¼Œä¸å¯å†åˆ†çš„åŸºç¡€å…ƒç´ 
   - ä¾‹å¦‚ï¼šè‹¹æžœã€æ¯å­ã€ä¹¦æœ¬ã€é’¥åŒ™ã€æ‰‹æœºã€é’±åŒ…ç­‰
   - è¿™äº›ç‰©å“é€šå¸¸ä¸ä¼šå†åŒ…å«å…¶ä»–ç‰©å“

2. **å®¹å™¨èŠ‚ç‚¹ (container)**: å¯åŒ…å«å…¶ä»–èŠ‚ç‚¹çš„å…ƒç´ 
   - **ç‰©ç†å®¹å™¨**: æ¡Œå­ã€æŠ½å±‰ã€æˆ¿é—´ã€æŸœå­ã€ç®±å­ã€ä¹¦æž¶ç­‰
   - **äººç‰©å®¹å™¨**: äººç‰©å¯ä»¥æºå¸¦ç‰©å“ã€ç©¿ç€è¡£ç‰©ã€æŒæœ‰é“å…·
   - **æŠ½è±¡å®¹å™¨**: æƒ³æ³•ã€è®¡åˆ’ã€ç³»ç»Ÿã€æ¦‚å¿µç­‰

## åˆ¤æ–­è§„åˆ™

1. å¦‚æžœä¸€ä¸ªå…ƒç´ å¯èƒ½åŒ…å«å…¶ä»–ç‰©å“ï¼Œåˆ™æ ‡è®°ä¸ºå®¹å™¨èŠ‚ç‚¹
2. äººç‰©é»˜è®¤å¯ä»¥ä½œä¸ºå®¹å™¨èŠ‚ç‚¹ï¼ˆå¯ä»¥æºå¸¦ç‰©å“ã€ç©¿ç€è¡£ç‰©ï¼‰
3. å®¶å…·ç±»ï¼ˆæ¡Œå­ã€æŸœå­ã€åºŠç­‰ï¼‰é€šå¸¸æ˜¯å®¹å™¨èŠ‚ç‚¹
4. å°åž‹ç‰©å“ï¼ˆæ¯å­ã€ç¬”ã€æ‰‹æœºç­‰ï¼‰é€šå¸¸æ˜¯ç‰©å“èŠ‚ç‚¹
5. æ ¹æ®åœºæ™¯ä¸»é¢˜åˆ¤æ–­æ˜¯å¦éœ€è¦å±•å¼€å®¹å™¨

## è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–æ–‡å­—ã€‚

```json
{
  "nodes": [
    {
      "name": "èŠ‚ç‚¹åç§°",
      "node_type": "item æˆ– container",
      "container_type": "physical/character/abstractï¼ˆä»…å®¹å™¨èŠ‚ç‚¹éœ€è¦ï¼‰",
      "description": "è¯¦ç»†æè¿°",
      "position": "ä½ç½®æè¿°",
      "attributes": {
        "material": "æè´¨",
        "color": "é¢œè‰²",
        "size": "å¤§å°",
        "condition": "çŠ¶æ€"
      },
      "should_expand": true/falseï¼ˆå®¹å™¨èŠ‚ç‚¹æ˜¯å¦éœ€è¦å±•å¼€ï¼‰
    }
  ],
  "reasoning": "ç”Ÿæˆè¿™äº›èŠ‚ç‚¹çš„ç†ç”±"
}
```"""

    @staticmethod
    def get_initial_generation_prompt(context: str) -> str:
        """èŽ·å–åˆå§‹ç”Ÿæˆæç¤ºè¯"""
        return f"""è¯·æ ¹æ®ä»¥ä¸‹åœºæ™¯ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆåœºæ™¯ä¸­çš„ä¸»è¦å…ƒç´ èŠ‚ç‚¹ã€‚

{context}

è¯·ç”Ÿæˆåœºæ™¯ä¸­çš„ä¸»è¦ç‰©å“å’Œå®¹å™¨èŠ‚ç‚¹ã€‚æ³¨æ„ï¼š
1. æ ¹æ®åœºæ™¯éœ€æ±‚åˆç†åˆ†é…ç‰©å“å’Œå®¹å™¨
2. è€ƒè™‘æ—¶ä»£èƒŒæ™¯å’Œåœºæ™¯æ°›å›´
3. äººç‰©å¯ä»¥ä½œä¸ºå®¹å™¨èŠ‚ç‚¹
4. æ ‡è®°å®¹å™¨èŠ‚ç‚¹æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥å±•å¼€

è¯·ç›´æŽ¥è¾“å‡ºJSONæ ¼å¼çš„ç»“æžœã€‚"""

    @staticmethod
    def get_container_expansion_prompt(
        container_name: str,
        container_type: str,
        container_description: str,
        parent_theme: str,
        level: int,
        context: str
    ) -> str:
        """èŽ·å–å®¹å™¨å±•å¼€æç¤ºè¯"""
        return f"""è¯·å±•å¼€ä»¥ä¸‹å®¹å™¨èŠ‚ç‚¹çš„å†…éƒ¨å†…å®¹ã€‚

## å®¹å™¨ä¿¡æ¯
- åç§°: {container_name}
- ç±»åž‹: {container_type}
- æè¿°: {container_description}
- å½“å‰å±‚çº§: {level}
- çˆ¶çº§ä¸»é¢˜: {parent_theme}

## åœºæ™¯ä¸Šä¸‹æ–‡
{context}

## å±•å¼€è§„åˆ™
1. å±‚çº§æ·±åº¦ä¸º {level}ï¼Œæœ€å¤§æ·±åº¦å»ºè®®ä¸è¶…è¿‡5å±‚
2. æ ¹æ®å®¹å™¨ç±»åž‹å’Œä¸»é¢˜å†³å®šå±•å¼€å†…å®¹
3. å¦‚æžœå±‚çº§è¾ƒæ·±ï¼ˆ>=4ï¼‰ï¼Œå°½é‡ç”Ÿæˆç‰©å“èŠ‚ç‚¹è€Œéžå®¹å™¨
4. å†…å®¹è¦ç¬¦åˆåœºæ™¯çš„æ—¶ä»£èƒŒæ™¯å’Œæ°›å›´
5. å¦‚æžœå®¹å™¨å†…å®¹å¯¹åœºæ™¯ä¸é‡è¦ï¼Œå¯ä»¥è¿”å›žç©ºèŠ‚ç‚¹åˆ—è¡¨

è¯·ç”Ÿæˆè¯¥å®¹å™¨å†…éƒ¨çš„ç‰©å“å’Œå®¹å™¨èŠ‚ç‚¹ï¼Œç›´æŽ¥è¾“å‡ºJSONæ ¼å¼ã€‚"""

    @staticmethod
    def get_parallel_expansion_prompt(
        containers: List[Dict[str, Any]],
        context: str
    ) -> str:
        """èŽ·å–å¹¶è¡Œå±•å¼€æç¤ºè¯ï¼ˆæ‰¹é‡å¤„ç†å¤šä¸ªå®¹å™¨ï¼‰"""
        containers_info = "\n".join([
            f"- {c['name']} (ç±»åž‹: {c['container_type']}, å±‚çº§: {c['level']}, ä¸»é¢˜: {c['theme']})"
            for c in containers
        ])
        
        return f"""è¯·æ‰¹é‡å±•å¼€ä»¥ä¸‹å®¹å™¨èŠ‚ç‚¹çš„å†…éƒ¨å†…å®¹ã€‚

## å¾…å±•å¼€å®¹å™¨åˆ—è¡¨
{containers_info}

## åœºæ™¯ä¸Šä¸‹æ–‡
{context}

## è¾“å‡ºæ ¼å¼
è¯·ä¸ºæ¯ä¸ªå®¹å™¨ç”Ÿæˆå†…éƒ¨èŠ‚ç‚¹ï¼Œè¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š

```json
{{
  "expansions": [
    {{
      "container_name": "å®¹å™¨åç§°",
      "nodes": [
        {{
          "name": "èŠ‚ç‚¹åç§°",
          "node_type": "item æˆ– container",
          ...
        }}
      ]
    }}
  ]
}}
è¯·ç›´æŽ¥è¾“å‡ºJSONæ ¼å¼çš„ç»“æžœã€‚"""

    @staticmethod
    def get_round_summary_prompt(
        round_num: int,
        current_nodes: List[Dict[str, Any]],
        context: str,
        previous_summary: str = ""
    ) -> str:
        """èŽ·å–è½®æ¬¡æ€»ç»“æç¤ºè¯"""
        
        # æ ¼å¼åŒ–å½“å‰èŠ‚ç‚¹ç»“æž„
        nodes_summary = []
        for node in current_nodes:
            node_type_display = "ðŸ“¦ å®¹å™¨" if node.get('node_type') == 'container' else "ðŸ“„ ç‰©å“"
            container_type = f"({node.get('container_type', 'physical')})" if node.get('node_type') == 'container' else ""
            nodes_summary.append(f"- {node_type_display} {node['name']} {container_type} [å±‚çº§:{node.get('level',0)}]")
        
        nodes_text = "\n".join(nodes_summary) if nodes_summary else "  æš‚æ— èŠ‚ç‚¹"
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœºæ™¯è®¾è®¡å¸ˆï¼Œè´Ÿè´£å¯¹åœºæ™¯ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œè´¨é‡æŽ§åˆ¶å’Œä¼˜åŒ–ã€‚
å½“å‰çŠ¶æ€
è½®æ¬¡: ç¬¬ {round_num} è½®

åœºæ™¯ä¸Šä¸‹æ–‡: {context}

å½“å‰å·²ç”Ÿæˆçš„èŠ‚ç‚¹
{nodes_text}

ä¸Šä¸€è½®æ€»ç»“
{previous_summary if previous_summary else "è¿™æ˜¯ç¬¬ä¸€è½®ï¼Œå°šæ— æ€»ç»“"}

ä½ çš„ä»»åŠ¡
è¯·åˆ†æžå½“å‰åœºæ™¯çš„èŠ‚ç‚¹ï¼Œå¹¶å›žç­”ä»¥ä¸‹é—®é¢˜ï¼š

å®Œæ•´æ€§æ£€æŸ¥ï¼šå½“å‰èŠ‚ç‚¹æ˜¯å¦å®Œæ•´è¦†ç›–äº†åœºæ™¯éœ€æ±‚ï¼Ÿè¿˜ç¼ºå°‘å“ªäº›å…³é”®å…ƒç´ ï¼Ÿ

åˆç†æ€§æ£€æŸ¥ï¼šèŠ‚ç‚¹çš„å±‚æ¬¡å…³ç³»æ˜¯å¦åˆç†ï¼Ÿæ˜¯å¦æœ‰èŠ‚ç‚¹åº”è¯¥åˆå¹¶æˆ–æ‹†åˆ†ï¼Ÿ

å†—ä½™æ£€æŸ¥ï¼šå“ªäº›èŠ‚ç‚¹æ˜¯å¤šä½™çš„ã€ä¸å¿…è¦çš„ï¼Ÿï¼ˆè¯·å°½é‡ç²¾ç®€ï¼Œåˆ é™¤å†—ä½™èŠ‚ç‚¹ï¼‰

æ·±åº¦æŽ§åˆ¶ï¼šå“ªäº›å®¹å™¨åº”è¯¥ç»§ç»­å±•å¼€ï¼ˆä¸‹ä¸€è½®å±•å¼€ï¼‰ï¼Ÿå“ªäº›åº”è¯¥åœæ­¢ï¼Ÿ

ä¼˜åŒ–å»ºè®®ï¼šéœ€è¦å¢žåŠ ä»€ä¹ˆèŠ‚ç‚¹ï¼Ÿåˆ é™¤ä»€ä¹ˆèŠ‚ç‚¹ï¼Ÿä¿®æ”¹ä»€ä¹ˆèŠ‚ç‚¹ï¼Ÿ

è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š
```json
{{
  "summary": "æœ¬è½®æ€»ç»“ï¼Œç®€è¦æè¿°åœºæ™¯ç”ŸæˆçŠ¶æ€",
  "completeness_score": 0-100çš„å®Œæ•´æ€§è¯„åˆ†,
  "issues_found": [
    "é—®é¢˜1",
    "é—®é¢˜2"
  ],
  "optimization_suggestions": [
    {{
      "action": "add/remove/modify",
      "target_node": "èŠ‚ç‚¹åç§°",
      "suggestion": "å…·ä½“å»ºè®®",
      "node_data": {{}}  # å¦‚æžœæ˜¯addæˆ–modifyï¼Œæä¾›æ–°çš„èŠ‚ç‚¹æ•°æ®
    }}
  ],
  "containers_to_expand_next": [
    {{
      "name": "å®¹å™¨åç§°",
      "reason": "å±•å¼€ç†ç”±",
      "priority": 1-5çš„ä¼˜å…ˆçº§ï¼ˆ5æœ€é«˜ï¼‰
    }}
  ],
  "containers_to_stop": [
    {{
      "name": "å®¹å™¨åç§°",
      "reason": "åœæ­¢ç†ç”±"
    }}
  ],
  "next_round_focus": "ä¸‹ä¸€è½®åº”è¯¥é‡ç‚¹å…³æ³¨çš„æ–¹å‘"
}}
```"""

    @staticmethod
    def get_optimization_prompt(
        optimization_suggestions: List[Dict[str, Any]],
        current_nodes: List[Dict[str, Any]],
        context: str
    ) -> str:
        """èŽ·å–èŠ‚ç‚¹ä¼˜åŒ–æç¤ºè¯"""
        
        suggestions_text = "\n".join([
            f"- {s['action']} {s.get('target_node', '')}: {s['suggestion']}"
            for s in optimization_suggestions
        ])
        
        return f"""è¯·æ ¹æ®ä¼˜åŒ–å»ºè®®ï¼Œè°ƒæ•´å½“å‰åœºæ™¯çš„èŠ‚ç‚¹ã€‚

## åœºæ™¯ä¸Šä¸‹æ–‡
{context}

## ä¼˜åŒ–å»ºè®®
{suggestions_text}

## å½“å‰èŠ‚ç‚¹
{json.dumps(current_nodes, ensure_ascii=False, indent=2)}

## ä»»åŠ¡
è¯·æ ¹æ®ä¼˜åŒ–å»ºè®®ï¼Œç”Ÿæˆè°ƒæ•´åŽçš„èŠ‚ç‚¹åˆ—è¡¨ã€‚å¯ä»¥ç›´æŽ¥æ·»åŠ æ–°èŠ‚ç‚¹ã€ä¿®æ”¹çŽ°æœ‰èŠ‚ç‚¹æˆ–åˆ é™¤ä¸å¿…è¦çš„èŠ‚ç‚¹ã€‚

## è¾“å‡ºæ ¼å¼
```json
{{
  "updated_nodes": [
    {{
      "name": "èŠ‚ç‚¹åç§°",
      "node_type": "item/container",
      "container_type": "physical/character/abstractï¼ˆå®¹å™¨éœ€è¦ï¼‰",
      "description": "æè¿°",
      "position": "ä½ç½®",
      "attributes": {{}},
      "should_expand": true/false
    }}
  ]
}}
```"""


class SceneAIClient:
    """
    åœºæ™¯ç”Ÿæˆä¸“ç”¨AIå®¢æˆ·ç«¯
    
    å°è£…åœºæ™¯ç”Ÿæˆç›¸å…³çš„AIè°ƒç”¨
    """
    
    def __init__(self, config: Optional[AIConfig] = None):
        self.client = AIClient(config)
        self.prompts = SceneAIPrompts()
    
    def generate_initial_nodes(self, context: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆå§‹åœºæ™¯èŠ‚ç‚¹
        
        Args:
            context: åœºæ™¯ä¸Šä¸‹æ–‡æè¿°
        
        Returns:
            åŒ…å«èŠ‚ç‚¹åˆ—è¡¨çš„å­—å…¸
        """
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_initial_generation_prompt(context)}
        ]
        
        return self.client.chat(messages)
    
    async def generate_initial_nodes_async(self, context: str) -> Dict[str, Any]:
        """å¼‚æ­¥ç”Ÿæˆåˆå§‹åœºæ™¯èŠ‚ç‚¹"""
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_initial_generation_prompt(context)}
        ]
        
        return await self.client.chat_async(messages)
    
    def expand_container(
        self,
        container_name: str,
        container_type: str,
        container_description: str,
        parent_theme: str,
        level: int,
        context: str
    ) -> Dict[str, Any]:
        """
        å±•å¼€å®¹å™¨èŠ‚ç‚¹
        
        Args:
            container_name: å®¹å™¨åç§°
            container_type: å®¹å™¨ç±»åž‹
            container_description: å®¹å™¨æè¿°
            parent_theme: çˆ¶çº§ä¸»é¢˜
            level: å½“å‰å±‚çº§
            context: åœºæ™¯ä¸Šä¸‹æ–‡
        
        Returns:
            åŒ…å«å­èŠ‚ç‚¹åˆ—è¡¨çš„å­—å…¸
        """
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_container_expansion_prompt(
                container_name, container_type, container_description,
                parent_theme, level, context
            )}
        ]
        
        return self.client.chat(messages)
    
    async def expand_container_async(
        self,
        container_name: str,
        container_type: str,
        container_description: str,
        parent_theme: str,
        level: int,
        context: str
    ) -> Dict[str, Any]:
        """å¼‚æ­¥å±•å¼€å®¹å™¨èŠ‚ç‚¹"""
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_container_expansion_prompt(
                container_name, container_type, container_description,
                parent_theme, level, context
            )}
        ]
        
        return await self.client.chat_async(messages)
    
    async def expand_containers_parallel_async(
        self,
        containers: List[Dict[str, Any]],
        context: str
    ) -> Dict[str, Any]:
        """
        å¹¶è¡Œå±•å¼€å¤šä¸ªå®¹å™¨èŠ‚ç‚¹
        
        Args:
            containers: å®¹å™¨ä¿¡æ¯åˆ—è¡¨
            context: åœºæ™¯ä¸Šä¸‹æ–‡
        
        Returns:
            åŒ…å«æ‰€æœ‰å±•å¼€ç»“æžœçš„å­—å…¸
        """
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_parallel_expansion_prompt(containers, context)}
        ]
        
        return await self.client.chat_async(messages)
    
    def expand_containers_parallel(
        self,
        containers: List[Dict[str, Any]],
        context: str
    ) -> Dict[str, Any]:
        """åŒæ­¥å¹¶è¡Œå±•å¼€å¤šä¸ªå®¹å™¨èŠ‚ç‚¹"""
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_parallel_expansion_prompt(containers, context)}
        ]
        
        return self.client.chat(messages)
    
    def analyze_round(
        self,
        round_num: int,
        current_nodes: List[Dict[str, Any]],
        context: str,
        previous_summary: str = ""
    ) -> Dict[str, Any]:
        """
        åˆ†æžå½“å‰è½®æ¬¡çš„ç»“æžœ
        
        Args:
            round_num: å½“å‰è½®æ¬¡
            current_nodes: å½“å‰æ‰€æœ‰èŠ‚ç‚¹ï¼ˆå­—å…¸æ ¼å¼ï¼‰
            context: åœºæ™¯ä¸Šä¸‹æ–‡
            previous_summary: ä¸Šä¸€è½®æ€»ç»“
        
        Returns:
            åŒ…å«æ€»ç»“å’Œå»ºè®®çš„å­—å…¸
        """
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_round_summary_prompt(
                round_num, current_nodes, context, previous_summary
            )}
        ]
        
        return self.client.chat(messages)
    
    async def analyze_round_async(
        self,
        round_num: int,
        current_nodes: List[Dict[str, Any]],
        context: str,
        previous_summary: str = ""
    ) -> Dict[str, Any]:
        """å¼‚æ­¥åˆ†æžå½“å‰è½®æ¬¡çš„ç»“æžœ"""
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_round_summary_prompt(
                round_num, current_nodes, context, previous_summary
            )}
        ]
        
        return await self.client.chat_async(messages)
    
    def optimize_nodes(
        self,
        optimization_suggestions: List[Dict[str, Any]],
        current_nodes: List[Dict[str, Any]],
        context: str
    ) -> Dict[str, Any]:
        """
        æ ¹æ®å»ºè®®ä¼˜åŒ–èŠ‚ç‚¹
        """
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_optimization_prompt(
                optimization_suggestions, current_nodes, context
            )}
        ]
        
        return self.client.chat(messages)
    
    async def optimize_nodes_async(
        self,
        optimization_suggestions: List[Dict[str, Any]],
        current_nodes: List[Dict[str, Any]],
        context: str
    ) -> Dict[str, Any]:
        """å¼‚æ­¥ä¼˜åŒ–èŠ‚ç‚¹"""
        messages = [
            {"role": "system", "content": self.prompts.get_system_prompt()},
            {"role": "user", "content": self.prompts.get_optimization_prompt(
                optimization_suggestions, current_nodes, context
            )}
        ]
        
        return await self.client.chat_async(messages)